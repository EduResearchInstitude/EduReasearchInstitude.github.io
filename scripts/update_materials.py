import json
import os
import requests
from bs4 import BeautifulSoup
import time
import random
from datetime import datetime

# ê¸°ì¡´ ìë£Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_existing_materials():
    try:
        with open('data/all_materials.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

# ìƒˆ ìë£Œì¸ì§€ í™•ì¸
def is_new_material(materials, title, institute):
    for material in materials:
        if material['title'] == title and material['institute'] == institute:
            return False
    return True

# ì—°êµ¬ì› ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def load_institutes():
    try:
        with open('data/institutes.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

# ìë£Œ ì €ì¥í•˜ê¸°
def save_materials(materials):
    os.makedirs('data', exist_ok=True) # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    with open('data/all_materials.json', 'w', encoding='utf-8') as f:
        json.dump(materials, f, ensure_ascii=False, indent=2)

# ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_seoul_institute(materials, institute_info):
    base_url = "https://serii.sen.go.kr"
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")
    
    try:
        # ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì› ì •ì±…ì—°êµ¬ ìë£Œì‹¤ í˜ì´ì§€
        research_url = f"{base_url}/web/serii/7/10"
        response = requests.get(research_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        # ê²Œì‹œê¸€ ëª©ë¡ ì°¾ê¸° (ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        items = soup.select('.board-list tbody tr')
        
        for item in items:
            try:
                # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
                title_elem = item.select_one('td.subject a')
                date_elem = item.select_one('td.date')
                
                if not title_elem:
                    continue
                    
                title = title_elem.get_text(strip=True)
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    if link.startswith('/'):
                        link = base_url + link
                    else:
                        link = base_url + '/' + link
                
                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"seoul_{len(materials) + 1:03d}"
                    
                    # ìë£Œ ìœ í˜• íŒë‹¨
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "êµìˆ˜í•™ìŠµìë£Œ" in title or "ìˆ˜ì—…ìë£Œ" in title:
                        detected_type = "guide"
                    
                    # ì—°ë„ ì¶”ì¶œ
                    detected_year = datetime.now().year
                    if date_elem:
                        date_text = date_elem.get_text(strip=True)
                        try:
                            if '-' in date_text:
                                detected_year = int(date_text.split('-')[0])
                            elif '.' in date_text:
                                detected_year = int(date_text.split('.')[0])
                        except:
                            pass
                    
                    # íƒœê·¸ ì¶”ì¶œ
                    detected_tags = ["ì„œìš¸", "êµìœ¡ì—°êµ¬"]
                    keywords = ["êµìœ¡ê³¼ì •", "êµìœ¡ì •ì±…", "ë¯¸ë˜êµìœ¡", "AI", "ê³¼í•™", "ìˆ˜í•™", "ì§„ë¡œ", "êµì›"]
                    for keyword in keywords:
                        if keyword in title:
                            detected_tags.append(keyword)
                    
                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": str(detected_year),
                        "tags": detected_tags,
                        "url": link
                    }
                    
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_busan_institute(materials, institute_info):
    base_url = "https://www.beri.pe.kr"
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/bbs/board.php?bo_table=data", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')

        items = soup.select('table.board_list tr') 
        
        for item in items[1:]:
            try:
                title_elem = item.select_one('td.subject a') 
                date_elem = item.select_one('td.datetime') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ë¶€ì‚°ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "AI" in title: detected_tags.append("AI")
                    if "ë¯¸ë˜êµìœ¡" in title: detected_tags.append("ë¯¸ë˜êµìœ¡")
                    if "ì°½ì˜ì„±" in title: detected_tags.append("ì°½ì˜ì„±")
                    if "ìˆ˜í•™" in title: detected_tags.append("ìˆ˜í•™")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_daegu_institute(materials, institute_info):
    base_url = "https://www.dge.go.kr/"
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/board/list.do?boardId=BBS_0000008", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_list tbody tr') 
        
        for item in items:
            try:
                title_elem = item.select_one('td.title a') 
                date_elem = item.select_one('td.reg_dt') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ëŒ€êµ¬ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "ìœµí•©í”„ë¡œì íŠ¸" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ì°½ì˜" in title: detected_tags.append("ì°½ì˜")
                    if "ìœµí•©" in title: detected_tags.append("ìœµí•©")
                    if "ê³¼í•™" in title: detected_tags.append("ê³¼í•™")
                    if "ìˆ˜í•™" in title: detected_tags.append("ìˆ˜í•™")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_incheon_institute(materials, institute_info):
    base_url = "https://ienet.ice.go.kr/"
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/boardCnts/list.do?boardID=1624&m=0301&s=ice", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_type01 tbody tr') # ì˜ˆì‹œ ì…€ë ‰í„°
        
        for item in items:
            try:
                title_elem = item.select_one('td.tit a') 
                date_elem = item.select_one('td.date') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ì¸ì²œë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "íƒêµ¬ë³´ê³ ì„œ" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025.09.29 ë˜ëŠ” 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str.replace('.', '-'), '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ê³¼í•™" in title: detected_tags.append("ê³¼í•™")
                    if "ì •ë³´" in title: detected_tags.append("ì •ë³´")
                    if "í™˜ê²½" in title: detected_tags.append("í™˜ê²½")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_gwangju_institute(materials, institute_info):
    base_url = "https://gice.gen.go.kr/"
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        response = requests.get(f"{base_url}/cop/bbs/selectBoardList.do?bbsId=BBSMSTR_000000000101", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_list tbody tr') 
        
        for item in items:
            try:
                title_elem = item.select_one('td.subject a') 
                date_elem = item.select_one('td.reg_dt') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ê´‘ì£¼ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "ì°½ì˜ì²´í—˜" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) 
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ì°½ì˜" in title: detected_tags.append("ì°½ì˜")
                    if "ìœµí•©" in title: detected_tags.append("ìœµí•©")
                    if "êµìœ¡" in title: detected_tags.append("êµìœ¡")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials


# ë©”ì¸ í•¨ìˆ˜
def main():
    # ê¸°ì¡´ ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸°
    materials = load_existing_materials()
    print(f"ê¸°ì¡´ ìë£Œ ìˆ˜: {len(materials)}")
    
    # ì—°êµ¬ì› ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    institutes = load_institutes()
    if not institutes:
        print("ì—°êµ¬ì› ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° ì—°êµ¬ì›ë³„ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
    for institute in institutes:
        print(f"\n--------------------------------------------------")
        print(f"  > {institute['name']} ìë£Œ ìˆ˜ì§‘ ì‹œë„ ì¤‘...")
        
        if "ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì›" in institute['name']:
            materials = crawl_seoul_institute(materials, institute)
        elif "ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ" in institute['name']:
            materials = crawl_busan_institute(materials, institute)
        elif "ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì›" in institute['name']:
            materials = crawl_daegu_institute(materials, institute)
        elif "ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì›" in institute['name']:
            materials = crawl_incheon_institute(materials, institute)
        elif "ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì›" in institute['name']: 
            materials = crawl_gwangju_institute(materials, institute)
        else:
            print(f"  > {institute['name']} ì— ëŒ€í•œ í¬ë¡¤ë§ í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            
        # í¬ë¡¤ë§ ì‚¬ì´ì— ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€ ë° ì°¨ë‹¨ ë°©ì§€)
        time.sleep(random.uniform(2, 5)) # 2ì´ˆì—ì„œ 5ì´ˆ ì‚¬ì´ ëœë¤ ëŒ€ê¸°

    # ìˆ˜ì§‘í•œ ìë£Œ ì €ì¥
    save_materials(materials)
    print(f"\n--------------------------------------------------")
    print(f"ìë£Œ ìˆ˜ì§‘ ì™„ë£Œ. ì´ {len(materials)}ê°œì˜ ìë£Œê°€ ìˆìŠµë‹ˆë‹¤.")

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
