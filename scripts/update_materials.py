import json
import os
import requests
from bs4 import BeautifulSoup
import time
import random
from datetime import datetime

# ê¸°ì¡´ ìë£Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_existing_materials():
    try:
        with open('data/all_materials.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

# ìƒˆ ìë£Œì¸ì§€ í™•ì¸
def is_new_material(materials, title, institute):
    for material in materials:
        # ì œëª©ê³¼ ê¸°ê´€ì´ ê°™ê³ , URLë„ ê°™ìœ¼ë©´ ë™ì¼ ìë£Œë¡œ ê°„ì£¼ (URLê¹Œì§€ ë¹„êµí•˜ëŠ” ê²ƒì´ ë” ì •í™•í•¨)
        if material['title'] == title and material['institute'] == institute:
            return False
    return True

# ì—°êµ¬ì› ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
def load_institutes():
    try:
        with open('data/institutes.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

# ìë£Œ ì €ì¥í•˜ê¸°
def save_materials(materials):
    os.makedirs('data', exist_ok=True) # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    with open('data/all_materials.json', 'w', encoding='utf-8') as f:
        json.dump(materials, f, ensure_ascii=False, indent=2)

# ê° êµìœ¡ì—°êµ¬ì›ë³„ í¬ë¡¤ë§ í•¨ìˆ˜ (ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”)

# ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì› í¬ë¡¤ë§ í•¨ìˆ˜ (ìë£Œ ìœ í˜•, ì—°ë„, íƒœê·¸ ì¶”ì¶œ ë¡œì§ ê°•í™”)
def crawl_seoul_institute(materials, institute_info):
    base_url = institute_info['url']
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")
    
    try:
        # ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì›ì˜ 'ì—°êµ¬ë³´ê³ ì„œ' ìë£Œì‹¤ í˜ì´ì§€ (ì˜ˆì‹œ URL)
        report_url = f"{base_url}/cop/bbs/selectBoardList.do?bbsId=BBSMSTR_000000000121"
        response = requests.get(report_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_list tbody tr') # ê²Œì‹œê¸€ ëª©ë¡
        
        for item in items:
            try:
                title_elem = item.select_one('td.title a')
                date_elem = item.select_one('td.regdate') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue
                    
                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link # ìƒëŒ€ ê²½ë¡œ ì²˜ë¦¬

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ ğŸ’¡
                    # -------------------------------------------------------------
                    # 1. ìë£Œ ìœ í˜• (type): ì œëª©ì— 'ì§€ë„ì•ˆ', 'êµìœ¡ê³¼ì •' ë“± íŠ¹ì • í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ ìœ ì¶”
                    detected_type = "report" # ê¸°ë³¸ê°’
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title:
                        detected_type = "guide"
                    elif "êµìœ¡ê³¼ì •" in title or "ì •ì±…ì—°êµ¬" in title:
                        detected_type = "report" # ì´ë¯¸ ê¸°ë³¸ê°’ì´ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ
                    
                    # 2. ë°œí–‰ ì—°ë„ (year): ë“±ë¡ì¼ íƒœê·¸ì—ì„œ ì—°ë„ ì¶”ì¶œ (ì˜ˆì‹œ)
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            # ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ì¼ ê²½ìš° ì¶”ê°€ ì²˜ë¦¬ í•„ìš”
                            pass
                    else:
                        # ë‚ ì§œ íƒœê·¸ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì—°ë„ë¥¼ ì„ì‹œë¡œ ì‚¬ìš©
                        detected_year = str(datetime.now().year)

                    # 3. íƒœê·¸ (tags): ì œëª©ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ íƒœê·¸ë¡œ í™œìš©
                    detected_tags = [institute_info['region'], institute_info['id']] # ì§€ì—­, IDëŠ” ê¸°ë³¸ íƒœê·¸
                    if "AI" in title: detected_tags.append("AI")
                    if "ë¯¸ë˜êµìœ¡" in title: detected_tags.append("ë¯¸ë˜êµìœ¡")
                    if "ì§„ë¡œ" in title: detected_tags.append("ì§„ë¡œ")
                    if "ê³¼í•™" in title: detected_tags.append("ê³¼í•™")
                    if "ìˆ˜í•™" in title: detected_tags.append("ìˆ˜í•™")
                    # ê¸°íƒ€ í‚¤ì›Œë“œì— ë”°ë¼ íƒœê·¸ ì¶”ê°€ ë¡œì§ êµ¬í˜„
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,       # ì¶”ì¶œëœ ìœ í˜• ì‚¬ìš©
                        "year": detected_year,       # ì¶”ì¶œëœ ì—°ë„ ì‚¬ìš©
                        "tags": list(set(detected_tags)), # ì¤‘ë³µ íƒœê·¸ ì œê±°
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                    
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_busan_institute(materials, institute_info):
    base_url = institute_info['url']
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/bbs/board.php?bo_table=data", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')

        items = soup.select('table.board_list tr') 
        
        for item in items[1:]:
            try:
                title_elem = item.select_one('td.subject a') 
                date_elem = item.select_one('td.datetime') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ë¶€ì‚°ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "AI" in title: detected_tags.append("AI")
                    if "ë¯¸ë˜êµìœ¡" in title: detected_tags.append("ë¯¸ë˜êµìœ¡")
                    if "ì°½ì˜ì„±" in title: detected_tags.append("ì°½ì˜ì„±")
                    if "ìˆ˜í•™" in title: detected_tags.append("ìˆ˜í•™")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_daegu_institute(materials, institute_info):
    base_url = institute_info['url']
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/board/list.do?boardId=BBS_0000008", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_list tbody tr') 
        
        for item in items:
            try:
                title_elem = item.select_one('td.title a') 
                date_elem = item.select_one('td.reg_dt') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ëŒ€êµ¬ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "ìœµí•©í”„ë¡œì íŠ¸" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ì°½ì˜" in title: detected_tags.append("ì°½ì˜")
                    if "ìœµí•©" in title: detected_tags.append("ìœµí•©")
                    if "ê³¼í•™" in title: detected_tags.append("ê³¼í•™")
                    if "ìˆ˜í•™" in title: detected_tags.append("ìˆ˜í•™")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_incheon_institute(materials, institute_info):
    base_url = institute_info['url']
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› ìë£Œì‹¤ URL (ì˜ˆì‹œ)
        response = requests.get(f"{base_url}/boardCnts/list.do?boardID=1624&m=0301&s=ice", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_type01 tbody tr') # ì˜ˆì‹œ ì…€ë ‰í„°
        
        for item in items:
            try:
                title_elem = item.select_one('td.tit a') 
                date_elem = item.select_one('td.date') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ì¸ì²œë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "íƒêµ¬ë³´ê³ ì„œ" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) # ì˜ˆ: 2025.09.29 ë˜ëŠ” 2025-09-29
                        try:
                            detected_year = str(datetime.strptime(full_date_str.replace('.', '-'), '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ê³¼í•™" in title: detected_tags.append("ê³¼í•™")
                    if "ì •ë³´" in title: detected_tags.append("ì •ë³´")
                    if "í™˜ê²½" in title: detected_tags.append("í™˜ê²½")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials

# ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ í•¨ìˆ˜ (ì•ì„œ ì œê³µëœ ì½”ë“œ ìœ ì§€)
def crawl_gwangju_institute(materials, institute_info):
    base_url = institute_info['url']
    print(f"  > {institute_info['name']} í¬ë¡¤ë§ ì‹œì‘...")

    try:
        response = requests.get(f"{base_url}/cop/bbs/selectBoardList.do?bbsId=BBSMSTR_000000000101", timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        
        items = soup.select('table.board_list tbody tr') 
        
        for item in items:
            try:
                title_elem = item.select_one('td.subject a') 
                date_elem = item.select_one('td.reg_dt') # ë“±ë¡ì¼ íƒœê·¸ (ì˜ˆì‹œ)

                if not title_elem:
                    continue

                title = title_elem.get_text(strip=True).strip()
                link = title_elem.get('href')
                
                if link and not link.startswith('http'):
                    link = base_url + link

                if title and link and is_new_material(materials, title, institute_info['name']):
                    material_id = f"id_{institute_info['id']}_{len(materials) + 1}"
                    
                    # -------------------------------------------------------------
                    # ğŸ’¡ ê°œì„ ëœ ìë£Œ ì •ë³´ ì¶”ì¶œ ë¡œì§ (ê´‘ì£¼ë„ ë™ì¼í•˜ê²Œ ì ìš©) ğŸ’¡
                    # -------------------------------------------------------------
                    detected_type = "report"
                    if "ì§€ë„ì•ˆ" in title or "ìˆ˜ì—…ìë£Œ" in title or "ì°½ì˜ì²´í—˜" in title:
                        detected_type = "guide"
                    
                    detected_year = "ë¯¸ìƒ"
                    if date_elem:
                        full_date_str = date_elem.get_text(strip=True) 
                        try:
                            detected_year = str(datetime.strptime(full_date_str, '%Y-%m-%d').year)
                        except ValueError:
                            pass
                    else:
                        detected_year = str(datetime.now().year)

                    detected_tags = [institute_info['region'], institute_info['id']]
                    if "ì°½ì˜" in title: detected_tags.append("ì°½ì˜")
                    if "ìœµí•©" in title: detected_tags.append("ìœµí•©")
                    if "êµìœ¡" in title: detected_tags.append("êµìœ¡")
                    # -------------------------------------------------------------

                    new_material = {
                        "id": material_id,
                        "title": title,
                        "institute": institute_info['name'],
                        "type": detected_type,
                        "year": detected_year,
                        "tags": list(set(detected_tags)),
                        "url": link
                    }
                    materials.append(new_material)
                    print(f"    - ìƒˆ ìë£Œ ì¶”ê°€: {title} (ìœ í˜•: {detected_type}, ì—°ë„: {detected_year})")
            except Exception as e:
                print(f"    - ìë£Œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} in {institute_info['name']}")
                
    except requests.exceptions.RequestException as e:
        print(f"  > ìš”ì²­ ì˜¤ë¥˜: {institute_info['name']} - {e}")
    except Exception as e:
        print(f"  > ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì› í¬ë¡¤ë§ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
    
    return materials


# ë©”ì¸ í•¨ìˆ˜
def main():
    # ê¸°ì¡´ ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸°
    materials = load_existing_materials()
    print(f"ê¸°ì¡´ ìë£Œ ìˆ˜: {len(materials)}")
    
    # ì—°êµ¬ì› ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    institutes = load_institutes()
    if not institutes:
        print("ì—°êµ¬ì› ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° ì—°êµ¬ì›ë³„ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
    for institute in institutes:
        print(f"\n--------------------------------------------------")
        print(f"  > {institute['name']} ìë£Œ ìˆ˜ì§‘ ì‹œë„ ì¤‘...")
        
        if "ì„œìš¸êµìœ¡ì—°êµ¬ì •ë³´ì›" in institute['name']:
            materials = crawl_seoul_institute(materials, institute)
        elif "ë¶€ì‚°êµìœ¡ì—°êµ¬ì†Œ" in institute['name']:
            materials = crawl_busan_institute(materials, institute)
        elif "ëŒ€êµ¬ì°½ì˜ìœµí•©êµìœ¡ì›" in institute['name']:
            materials = crawl_daegu_institute(materials, institute)
        elif "ì¸ì²œêµìœ¡ê³¼í•™ì •ë³´ì›" in institute['name']:
            materials = crawl_incheon_institute(materials, institute)
        elif "ê´‘ì£¼ì°½ì˜ìœµí•©êµìœ¡ì›" in institute['name']: 
            materials = crawl_gwangju_institute(materials, institute)
        else:
            print(f"  > {institute['name']} ì— ëŒ€í•œ í¬ë¡¤ë§ í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            
        # í¬ë¡¤ë§ ì‚¬ì´ì— ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€ ë° ì°¨ë‹¨ ë°©ì§€)
        time.sleep(random.uniform(2, 5)) # 2ì´ˆì—ì„œ 5ì´ˆ ì‚¬ì´ ëœë¤ ëŒ€ê¸°

    # ìˆ˜ì§‘í•œ ìë£Œ ì €ì¥
    save_materials(materials)
    print(f"\n--------------------------------------------------")
    print(f"ìë£Œ ìˆ˜ì§‘ ì™„ë£Œ. ì´ {len(materials)}ê°œì˜ ìë£Œê°€ ìˆìŠµë‹ˆë‹¤.")

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
